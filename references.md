# Building with LLMs: References

## Multi-Agent Systems

- [How we built our multi-agent research system](https://www.anthropic.com/engineering/built-multi-agent-research-system) - Anthropic's detailed exploration of their multi-agent research system implementation, covering architecture, challenges, and practical applications.

## RAG (Retrieval Augmented Generation)

- [How to Improve RAG Applications: 6 Proven Strategies](https://jxnl.co/writing/2024/11/04/how-to-improve-rag-applications-6-proven-strategies/) - A practical guide covering six key strategies for improving RAG systems, from synthetic testing to query routing and user feedback collection.
- [Jason Liu's RAG Articles Collection](https://jxnl.co/writing/category/rag/) - A comprehensive collection of articles covering RAG fundamentals, implementation strategies, evaluation methods, and future predictions.

## Evaluation Methods

- [LLM Eval FAQ](https://hamel.dev/blog/posts/evals-faq/) - A comprehensive guide to evaluating LLM applications, covering best practices for RAG evaluation, model selection, annotation tools, and synthetic data generation.
- [There Are Only 6 RAG Evals](https://jxnl.co/writing/2025/05/19/there-are-only-6-rag-evals/) - A systematic framework for evaluating RAG systems based on six core relationships between questions, context, and answers.

## Production Best Practices

- [A Field Guide to Rapidly Improving AI Products](https://hamel.dev/blog/posts/field-guide/) - A comprehensive guide covering error analysis, data viewers, domain expert collaboration, synthetic data, evaluation trust, and experiment-based roadmaps.

## Security and Safety

- [An Introduction to Google's Approach for Secure AI Agents](https://research.google/pubs/an-introduction-to-googles-approach-for-secure-ai-agents/) - Google's framework for secure AI agents, emphasizing a hybrid defense-in-depth strategy combining traditional security controls with dynamic reasoning-based defenses.
- [Design Patterns for Securing LLM Agents against Prompt Injections](https://arxiv.org/html/2506.08837v2) - A comprehensive study of design patterns and best practices for building AI agents with provable resistance to prompt injection attacks.

# Building with LLMs: References

## Multi-Agent Systems

- [How we built our multi-agent research system](https://www.anthropic.com/engineering/built-multi-agent-research-system) - Anthropic's detailed exploration of their multi-agent research system implementation, covering architecture, challenges, and practical applications.

## RAG (Retrieval Augmented Generation)

- [How to Improve RAG Applications: 6 Proven Strategies](https://jxnl.co/writing/2024/11/04/how-to-improve-rag-applications-6-proven-strategies/) - A practical guide covering six key strategies for improving RAG systems, from synthetic testing to query routing and user feedback collection.
- [Jason Liu's RAG Articles Collection](https://jxnl.co/writing/category/rag/) - A comprehensive collection of articles covering RAG fundamentals, implementation strategies, evaluation methods, and future predictions.

## Evaluation Methods

- [LLM Eval FAQ](https://hamel.dev/blog/posts/evals-faq/) - A comprehensive guide to evaluating LLM applications, covering best practices for RAG evaluation, model selection, annotation tools, and synthetic data generation.
- [There Are Only 6 RAG Evals](https://jxnl.co/writing/2025/05/19/there-are-only-6-rag-evals/) - A systematic framework for evaluating RAG systems based on six core relationships between questions, context, and answers.

## Production Best Practices

- [A Field Guide to Rapidly Improving AI Products](https://hamel.dev/blog/posts/field-guide/) - A comprehensive guide covering error analysis, data viewers, domain expert collaboration, synthetic data, evaluation trust, and experiment-based roadmaps.

## Security and Safety

- [An Introduction to Google's Approach for Secure AI Agents](https://research.google/pubs/an-introduction-to-googles-approach-for-secure-ai-agents/) - Google's framework for secure AI agents, emphasizing a hybrid defense-in-depth strategy combining traditional security controls with dynamic reasoning-based defenses.
- [Design Patterns for Securing LLM Agents against Prompt Injections](https://arxiv.org/html/2506.08837v2) - A comprehensive study of design patterns and best practices for building AI agents with provable resistance to prompt injection attacks.
- [The Lethal Trifecta for AI Agents](https://simonwillison.net/2025/Jun/16/the-lethal-trifecta/) - A critical analysis of the three dangerous capabilities that can lead to data exfiltration in AI agents: private data access, untrusted content exposure, and external communication.

## AI Capabilities and Limitations

- [The Illusion of Self-Improvement: Why AI Can't Think Its Way to Genius](https://medium.com/@vishalmisra/the-illusion-of-self-improvement-why-ai-cant-think-its-way-to-genius-a355ef3e9fd5) - An insightful analysis of the fundamental limitations of AI systems in achieving true self-improvement and the misconceptions about AI's ability to think its way to superintelligence.

## Embeddings and Vector Spaces

- [Harnessing the Universal Geometry of Embeddings](https://arxiv.org/html/2505.12540v2) - A groundbreaking study demonstrating how to translate text embeddings between different vector spaces without paired data, with important implications for vector database security and information extraction.
